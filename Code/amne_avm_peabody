#!/Users/rjp34/anaconda3/bin/python
# -*- coding: utf-8 -*-
"""
Created on Tue May  1 10:55:10 2018

@author: rjp34
"""

#------------------------------------------------------------------------------
# Package imports

import math
import pandas as pd
import numpy as np
import sys

import datetime
import googlemaps
gmaps = googlemaps.Client(key = 'AIzaSyAH-15eBPnY88TcgXmWSIOqw0yFt3Kenj4')

from sklearn.model_selection import train_test_split
from sklearn import linear_model
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.ensemble import GradientBoostingRegressor


#------------------------------------------------------------------------------
def main():
    
    #------------------------------------
    # Get user inputs
    
    address = input('What is your address? ')
    print('Great. Now we just need some details about your house.')
    bedrooms = int(input('How many bedrooms does it have? '))
    bathrooms = int(input('How many bathrooms does it have? '))
    sqft_above = int(input('How many square feet is it? ' ))
    floors = float(input('How many floors does it have? '))
    waterfront = int(input('Does it have a view of the water? (1=Yes, 0=No) '))
    sqft_basement = int(input('How many square feet is the basement? (0 if no basement) '))
    yr_built = int(input('What year was it built? '))
    sqft_lot15 = int(input('How many square feet is the lot? '))
    renovated = int(input('Has it ever been renovated? (1=Yes, 0=No) '))
    month = datetime.datetime.now().month
    
    #------------------------------------
    # Check for data that the model was not trained on
    
    if bedrooms > 20 | sqft_above> 7000 | sqft_lot15 > 20000:
        print('This property cannot be safely modeled')
        sys.exit(0)
    
    #------------------------------------
    # Convert user address to lat and lon
    
    lon_lat = get_geocode(address)
    lon_q = lon_lat[0]
    lat_q = lon_lat[1]
    
    X_input = np.reshape([bedrooms, bathrooms, sqft_above, floors, waterfront, 
               sqft_basement, yr_built, lat_q, lon_q, sqft_lot15, month,
               renovated], (1, -1))
    
    # Load in King County dataset
    df = pd.read_csv('../Data/King_County/kc_house_data_cleaned.csv')
    df.drop('Unnamed: 0', axis = 1, inplace = True)
    
    #------------------------------------
    # Find distance between address and all other properties
    
    distance = []
    lon = df['long']
    lat = df['lat']
    for jj in range(0, len(lat)):
        d = haversine_distance([lon_q, lat_q], [lon[jj], lat[jj]])
        distance.append(d)
    df['distance'] = distance
    
    #------------------------------------
    # Find optimal radius for queried property
    
    [idx_ols, idx_gbr] = get_optimal_r(lon_q, lat_q, df)
    
    #------------------------------------
    # Build OLS model using optimal radii
    
    d_q = [i*int(1e3) for i in range(1, 40)]
    
    #------------------------------------
    # Get all properties within r_ols of queried location
    
    idx = df['distance'] <= d_q[idx_ols]
    df_local = df[idx]
    X_local = df_local.drop(['price', 'distance'], axis = 1).values
    y_local = df_local['price'].values
    
    # Train OLS model
    
    lin_reg = linear_model.LinearRegression()
    lin_reg.fit(X_local, y_local)
    y_pred_ols = float(lin_reg.predict(X_input))
    
    #------------------------------------
    # Build GBR model using optimal radii
    
    # Get all properties within r_ols of queried location
    idx = df['distance'] <= d_q[idx_gbr]
    df_local = df[idx]
    X_local = df_local.drop(['price', 'distance'], axis = 1).values
    y_local = df_local['price'].values
    
    # Train GBR model
    gbr = GradientBoostingRegressor(n_estimators = 100, learning_rate = 0.5, 
                                    max_depth = 5, random_state = 42, 
                                    loss = 'ls')
    gbr.fit(X_local, y_local)
    y_pred_gbr = float(gbr.predict(X_input))
    
    #------------------------------------
    # Return estimate
    
    print('Here are two estimates of your home\'s selling price: $',
          int(y_pred_ols*732/427), ' and $', int(y_pred_gbr*732/427))
    
    # The above introduces the scaling factor, based on the ratio of median 
    # home prices in March 2018 to median home prices in December 2014
    return [y_pred_ols*732/427, y_pred_gbr*732/427]
    
#------------------------------------------------------------------------------
# get_geocode returns (lon, lat), returned from the google maps API

def get_geocode(address):
    geocode_result = gmaps.geocode(address)
    lon_lat = geocode_result[0]['geometry']['location']
    return lon_lat['lng'], lon_lat['lat']

#------------------------------------------------------------------------------
# haversine_distance returns the great circle distance in meters between two
# points. 
def haversine_distance(lon_lat_1, lon_lat_2):
    lon_1, lat_1 = lon_lat_1
    lon_2, lat_2 = lon_lat_2
    radius = 6371e3 # m

    d_lat = math.radians(lat_2 - lat_1)
    d_lon = math.radians(lon_2 - lon_1)
    a = math.sin(d_lat/2) * math.sin(d_lat/2) + math.cos(math.radians(lat_1)) \
        * math.cos(math.radians(lat_2)) * math.sin(d_lon/2) * math.sin(d_lon/2)
    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))
    d = radius * c

    return d

#------------------------------------------------------------------------------
# get_optimal_r returns the optimal radius of properties to include for the
# queried lon, lat
def get_optimal_r(lon_q, lat_q, df):
    # Define range of distances to look in
    d_q = [i*int(1e3) for i in range(1, 40)] # 1 km to 40 km
    
    rmse_ols = []
    r2_ols = []
    rmse_gbr = []
    r2_gbr = []
    # Loop over distances, and estimate RMSE and r^2 for OLS and GBR
    ii = 1
    for r in d_q:

        print('Calculating...loop ', ii, ' of ', len(d_q))
        ii += 1
        # Get all properties within r of queried location
        idx = df['distance'] <= r
        df_local = df[idx]
        
        # We need a certain number of properties to train our model on
        if len(df_local) >= 50:
            X_local = df_local.drop(['price', 'distance'], axis = 1).values
            y_local = df_local['price'].values
            
            # Split data for training and testing
            X_train_local, X_test_local, y_train_local, y_test_local =  train_test_split(X_local, y_local, test_size = 0.3)
        
            # OLS
            lin_reg = linear_model.LinearRegression()
            lin_reg.fit(X_train_local, y_train_local)
            y_pred_ols = lin_reg.predict(X_test_local)
            rmse_ols.append(np.sqrt(mean_squared_error(y_test_local, 
                                                       y_pred_ols)))
            r2_ols.append(r2_score(y_test_local, y_pred_ols))
            
            # GBR
            gbr = GradientBoostingRegressor(n_estimators = 100, learning_rate = 0.5, max_depth = 5, 
                                            random_state = 42, loss = 'ls')
            gbr.fit(X_train_local, y_train_local)
            y_pred_gbr = gbr.predict(X_test_local)
            rmse_gbr.append(np.sqrt(mean_squared_error(y_test_local, 
                                                       y_pred_gbr)))
            r2_gbr.append(r2_score(y_test_local, y_pred_gbr))
    
    # Find index of optimal r2
    idx_ols = np.argmax(r2_ols)
    idx_gbr = np.argmax(r2_gbr)
            
    return[idx_ols, idx_gbr]
    
            
    
    
    


#------------------------------------------------------------------------------
# Boilerplate

if __name__ == '__main__':
    main()